# ARIA - Claude Context File

> Contexte pour reprendre ARIA √† tout moment. **Ne pas supprimer.**

## Identit√©

**ARIA** = Autonomous Recursive Intelligence Architecture

IA exp√©rimentale o√π l'intelligence **√©merge** de cellules vivantes. Pas un LLM - un syst√®me de vie artificielle.

## Philosophie

ARIA est **cultiv√©e**, pas programm√©e.

- **Cellules vivantes** : √©nergie, d√©sirs, ADN (pas des neurones)
- **√âvolution** : les comportements r√©ussis survivent (pas d'entra√Ænement)
- **√âmergence** : comportement complexe de r√®gles simples
- **D√©sir** : les cellules *veulent* agir (pas de loss function)

## Architecture

```
aria-body (MacBook)  ‚óÑ‚îÄ‚îÄWebSocket‚îÄ‚îÄ‚ñ∫  aria-brain (PC + RTX 2070)
   Interface TUI                         50k+ cellules vivantes
```

**Workspace Rust** :
- `aria-core` : Types compacts GPU-ready
- `aria-compute` : CPU/GPU backends, sparse updates
- `aria-brain` : Substrate, m√©moire, serveur WebSocket
- `aria-body` : Interface texte

## Ce qu'ARIA sait faire

- **Ressentir** : joie, curiosit√©, ennui, confort via tension physique
- **Apprendre** : feedback ("Bravo!"/"Non"), renforcement
- **Se souvenir** : m√©moire √©pisodique, "premi√®res fois"
- **Vivre** : r√™ves, spontan√©it√©, jeu cr√©atif
- **S'adapter** : param√®tres qui √©voluent avec le feedback
- **Explorer** : curiosit√©-driven, teste des combinaisons nouvelles
- **M√©ta-apprendre** : s'auto-√©value, apprend √† apprendre (Session 14)
- **Voir** : images ‚Üí vecteurs s√©mantiques 32D (Session 15)
- **S'auto-modifier (Session 16)** : analyse ses performances et change ses propres param√®tres
- **S'auto-√©voluer (Genesis)** : traduit son DNA en code GPU WGSL, recompile ses pipelines √† chaud (Session 23)
- **Intelligence physique (Session 31)** : comportement √©merge des lois physiques, pas du vocabulaire
- **Apprendre du web (Session 33)** : fetch Wikipedia/Wikiquote, extrait connaissances, injecte dans substrate
- **Parler sans LLM (Session 33)** : expressions √©mergentes par r√©sonance avec patterns appris

## Commandes

```bash
task brain          # 50k cellules, auto GPU/CPU
task brain-100k     # 100k cellules
ARIA_BACKEND=gpu task brain  # Forcer GPU (AMD/NVIDIA via Vulkan)
task body           # Interface
task stats          # Stats du cerveau
task episodes       # M√©moire √©pisodique
./scripts/run_overnight.sh   # Training autonome 24h (Session 33)
# Note: task words et task associations supprim√©s (Session 31)
```

## Param√®tres cl√©s

```rust
// Population
target_cells = 50_000 (configurable via ARIA_CELLS)

// Sparse updates (√©conomie CPU)
idle_ticks_to_sleep = 100
wake_threshold = 0.1

// Adaptatifs (√©voluent avec feedback)
emission_threshold: 0.05-0.5
response_probability: 0.3-1.0
spontaneity: 0.01-0.3
```

## Prochaines √©tapes

1. ‚úÖ **GPU compute** : wgpu/Vulkan - AMD Radeon NAVI14 fonctionnel
2. ‚úÖ **M√©ta-apprentissage** : ARIA s'auto-√©value et apprend √† apprendre
3. ‚úÖ **Perception visuelle** : images ‚Üí vecteurs s√©mantiques 32D
4. ‚úÖ **Auto-modification** : ARIA modifie ses propres param√®tres (Session 16)
5. ‚úÖ **Architecture 5M+ cellules** : SoA, Hysteresis, Spatial Hash GPU (Session 20)
6. ‚úÖ **Auto-√©volution structurelle** : JIT compilation, traduction DNA -> WGSL (Session 23)
7. ‚úÖ **Exploration du Code Binaire** : JIT, Shadow Brain, Attention S√©lective (Phase 5 termin√©e)
8. ‚úÖ **Loi de Pr√©diction** : Cellules qui pr√©disent leur futur gagnent de l'√©nergie (Session 25)

## Contexte personnel

Chats de Mickael :
- **Moka** : Bengal (ARIA le conna√Æt bien)
- **Obrigada** : Abyssin

---
*Version : 0.9.7 | Derni√®re update : 2026-01-04*

### Session 32 - Full GPU Migration (CPU Liberation)

**√âlimination des boucles O(n) CPU - le GPU fait TOUT le travail de propagation.**

#### Philosophie

Le CPU ne devrait g√©rer que :
1. Logique de haut niveau (m√©moire, d√©cisions)
2. I/O r√©seau (WebSocket, HTTP)
3. Gestion dynamique des Vec (naissance/mort)

Le GPU g√®re :
1. Propagation des signaux (spatial hash)
2. Physique des cellules (√©nergie, √©tat)
3. Lois d'intelligence (Pr√©diction, Hebb, Cluster)

#### Boucles CPU supprim√©es

| Fonction | Avant | Apr√®s | Gain |
|----------|-------|-------|------|
| `inject_signal()` | O(n) loop + distance calc | Buffer only | ~100% |
| `propagate_signal()` | O(n) loop | Buffer only | ~100% |
| `conceptualize()` | O(n) full scan | 5k sampling | 200√ó @ 1M |
| `spatial_view()` | O(n) full scan | 10k sampling | 100√ó @ 1M |
| `natural_selection()` | O(n) count + bucket | 5k+10k sampling | 100√ó @ 1M |
| `population_control()` | O(n) collect + sort | 5k sampling | 100√ó @ 1M |
| `sync GPU flags` | O(n) every 1000 ticks | **REMOVED** | ‚àû |
| `age increment` | O(n) every 100 ticks | **REMOVED** | ‚àû |

#### Code supprim√©

```rust
// signals.rs - AVANT (O(n) loop)
for (i, state) in self.states.iter_mut().enumerate() {
    let distance = Self::semantic_distance(&state.position, &target_position);
    // ... process each cell ...
}

// APR√àS (GPU-only)
// Signal added to buffer, GPU's SIGNAL_WITH_SPATIAL_HASH_SHADER handles:
// - Waking sleeping cells
// - Injecting tension into cell state
// - Resonance-based energy (La Vraie Faim)
// - Hebbian connection propagation
let mut buffer = self.signal_buffer.write();
buffer.push(fragment);
```

#### Sampling pour visualisation

```rust
// spatial_view() - 10k samples au lieu de O(n)
let sample_size = 10_000.min(self.cells.len());
for _ in 0..sample_size {
    let idx = rng.gen_range(0..self.cells.len());
    // ... process sampled cell ...
}
// Population extrapolated from sample
```

#### Fichiers modifi√©s

| Fichier | Changement |
|---------|------------|
| `aria-brain/src/substrate/signals.rs` | CPU loops ‚Üí buffer only |
| `aria-brain/src/substrate/emergence.rs` | O(n) ‚Üí 5k sampling |
| `aria-brain/src/substrate/mod.rs` | O(n) ‚Üí 10k sampling, removed sync loops |
| `aria-brain/src/substrate/lifecycle.rs` | O(n) ‚Üí sampling, removed Gen0 drain CPU loop |

#### Performance attendue @ 1M cellules

| M√©trique | Avant | Apr√®s |
|----------|-------|-------|
| `inject_signal()` | ~50ms | <1ms |
| `spatial_view()` | ~100ms | ~10ms |
| CPU utilisation tick | 80%+ | <20% |
| GPU utilisation | 30% | 80%+ |

#### Fix GPU Buffer Reallocation (Session 32 Part 2)

**Le freeze restant venait de r√©allocations GPU constantes.**

Sympt√¥me : Logs montraient `üéÆ GPU SoA: Allocating XXX MB` toutes les ~100 ticks, avec recompilation de tous les pipelines.

**Causes identifi√©es :**

1. **Headroom insuffisant** : Seulement 20% de marge
   - √Ä 500 nouvelles cellules/100 ticks, le headroom √©tait √©puis√© instantan√©ment
   - Chaque d√©passement ‚Üí r√©allocation compl√®te (700+ MB) + recompilation shaders

2. **Condition de r√©allocation trop agressive** :
   ```rust
   // AVANT: r√©allocation √† CHAQUE changement de taille
   let first_init = !self.initialized || self.cell_count != cells.len();

   // APR√àS: seulement quand on D√âPASSE la capacit√©
   let needs_realloc = !self.initialized || cells.len() > self.max_cell_count;
   ```

**Fix appliqu√©s :**

```rust
// gpu_soa.rs - Headroom 20% ‚Üí 100%
let cell_count_with_headroom = cell_count * 2;  // AVANT: cell_count + cell_count / 5

// Logique de r√©allocation optimis√©e
if needs_realloc {
    self.init_buffers(...);  // R√©allocation compl√®te
} else if size_changed {
    self.cell_count = cells.len();  // Juste mise √† jour du compteur
    self.upload_cells(states);      // Upload partiel OK
}
```

**R√©sultat :**
- R√©allocation : ~1x/heure au lieu de ~10x/seconde
- Freezes √©limin√©s pendant la reproduction normale

#### Fix Vec + GPU Upload (Session 32 Part 3)

**Deux probl√®mes identifi√©s :**

1. **Vec r√©allocation** : Quand population d√©passe capacit√©, Rust copie tout (~350MB)
2. **GPU upload O(n)** : `upload_cells()` uploadait 1M cellules √† chaque naissance

**Fix appliqu√©s :**

```rust
// lifecycle.rs - Reserve dynamique (pas 2x au d√©marrage qui alloue 700MB!)
let current_cap = self.cells.capacity();
let needed = self.cells.len() + max_births;
if needed > current_cap {
    let extra = (current_cap / 10).max(1000);  // +10% chunks
    self.cells.reserve(extra);
    self.states.reserve(extra);
}

// gpu_soa.rs - Upload incr√©mental (nouvelles cellules seulement)
fn upload_new_cells(&self, states: &[CellState], old_count: usize) {
    // Offset = old_count * sizeof(CellEnergy)
    // Upload only states[old_count..new_count]
}

// Tick: O(births) au lieu de O(n)
} else if new_count > old_count {
    self.upload_new_cells(states, old_count);
    self.upload_new_dna(dna_pool, old_count);
}
```

**R√©sultat :**
- Vec : r√©allocation par chunks de 10% (pas tout d'un coup)
- GPU upload : ~500 cellules au lieu de 1M
- Startup : pas de 700MB d'allocation suppl√©mentaire

#### Fix Parallel Cell Creation (Session 32 Part 4)

**Cr√©ation s√©quentielle de 5M cellules = bloqu√© au d√©marrage.**

```rust
// AVANT: S√©quentiel (minutes pour 5M)
for i in 0..initial_cells {
    let dna = DNA::random();  // Chaque appel est lent
    // ...
}

// APR√àS: Parall√®le avec rayon (secondes pour 5M)
use rayon::prelude::*;
let cell_data: Vec<(Cell, CellState, DNA)> = (0..initial_cells)
    .into_par_iter()
    .map(|i| {
        let dna = DNA::random();
        let cell = Cell::new(i as u64, i as u32);
        let state = CellState::new();
        (cell, state, dna)
    })
    .collect();
```

**R√©sultat :** D√©marrage 5M cells en ~5 secondes au lieu de plusieurs minutes.

#### GPU Dynamic Buffer Limits (Session 32 Part 5)

**Le headroom GPU est maintenant dynamique selon le mat√©riel.**

```rust
// Query GPU's actual limits
let adapter_limits = adapter.limits();
let gpu_max_buffer = (adapter_limits.max_buffer_size as usize).min(1024 * 1024 * 1024);

// Cap headroom based on largest buffer (CellConnections = 144 bytes)
let connections_size = std::mem::size_of::<CellConnections>(); // 144 bytes
let max_cells_in_buffer = self.max_buffer_size / connections_size;
let cell_count_with_headroom = (cell_count * 2).min(max_cells_in_buffer);
```

**Limites par buffer @ 1GB max:**
| Buffer | Bytes/cell | Max cells |
|--------|------------|-----------|
| CellConnections | 144 | 7.4M |
| CellInternalState | 128 | 8.3M |
| CellPosition | 64 | 16.7M |

**R√©sultat :** ARIA s'adapte automatiquement au GPU disponible.

#### Adaptive Headroom & Population Cap (Session 32 Part 6)

**Probl√®me :** "Device lost" errors sur RTX 2070 et MacBook avec 3-5M cells.

**Cause :** R√©allocation GPU pendant l'expansion de population = VRAM temporairement doubl√©e.

**Solution :** Headroom dynamique + population cap automatique.

```rust
// Headroom bas√© sur la taille de population (pas de config!)
let headroom_factor = if cell_count > 3_000_000 {
    1.25  // 25% headroom pour >3M cells
} else if cell_count > 1_000_000 {
    1.5   // 50% headroom pour 1-3M cells
} else {
    2.0   // 100% headroom pour <1M cells
};

// Population capp√©e automatiquement √† la capacit√© GPU
let backend_max = self.backend.stats().max_capacity;
let safety_cap = (target * 2).min(backend_max);
```

**Cha√Æne automatique :**
```
GPU init ‚Üí adapter.limits() ‚Üí headroom factor ‚Üí max_cell_count ‚Üí safety_cap
```

**R√©sultat :** Z√©ro configuration, ARIA s'adapte au mat√©riel disponible.

| GPU | 5M cells | Headroom | Capacity | VRAM |
|-----|----------|----------|----------|------|
| RTX 2070 (8GB) | ‚úÖ | 25% | 6.25M | ~2.4GB |
| RTX 4090 (24GB) | ‚úÖ | 25% | 6.25M | ~2.4GB |
| MacBook Intel | ‚úÖ | 50% | 1.5M | ~600MB |

#### Fix Trivial Predictions (Session 32 Part 7)

**Probl√®me :** Population croissait de 1M √† 1.006M sans interaction.

**Cause :** Le `PREDICTION_EVALUATE_SHADER` r√©compensait les "pr√©dictions triviales" :
- Cellules Gen0 sans connexions pr√©disent `[0,0,0,0,0,0,0,0]`
- √âtat r√©el reste `[0,0,0,0,0,0,0,0]` (pas de signaux)
- Accuracy = 1.0 (parfait!)
- Reward = 1.0 √ó 0.05 √ó 0.02 = 0.001 √©nergie par cellule
- Avec 1M cellules : 1000 √©nergie/tick = 500k √©nergie en 500 ticks

**Fix :** Skip les cellules sans activit√© r√©elle.

```wgsl
// Calculate actual state magnitude - skip trivial predictions
var actual_magnitude = 0.0;
for (var i = 0u; i < 4u; i = i + 1u) {
    actual_magnitude += actual_state0[i] * actual_state0[i];
    actual_magnitude += actual_state1[i] * actual_state1[i];
}
actual_magnitude = sqrt(actual_magnitude);

// Skip cells with no meaningful activity
if actual_magnitude < 0.1 { return; }
```

**R√©sultat :** Population stable sans stimulation. Les cellules doivent M√âRITER leur √©nergie.

#### Fix Sleeping Drain & O(n) Loops (Session 32 Part 8)

**Probl√®me 1 :** Drain des cellules dormantes trop faible (0.1√ó cost_rest).

**Fix :** Les cellules dormantes paient le m√™me cost_rest que les √©veill√©es - elles respirent encore !

```wgsl
// AVANT: 0.1√ó = 0.00003/tick (survie ~27h!)
cell_energy.energy -= config.cost_rest * 0.1;

// APR√àS: 1.0√ó = 0.0003/tick (survie ~55min)
cell_energy.energy -= config.cost_rest;
```

**Probl√®me 2 :** Freezes avec 1M cells - boucles O(n) CPU restantes.

| Fonction | Avant | Apr√®s |
|----------|-------|-------|
| `stats()` | 4√ó O(n) loops | 5k sampling |
| `calculate_entropy()` | O(n) collect | 2k sampling |
| `generate_internal_signals()` | O(n) loop | Skip si disabled + 1k sampling |

**R√©sultat :**
- CPU savings : de ~100ms/call √† <1ms/call
- Population d√©croit naturellement sans stimulation (La Vraie Faim effective)

#### Fix GPU Signal Shader (Session 32 Part 9)

**Probl√®me critique :** Le shader SIGNAL_TEMPLATE (legacy <100k cells) ne traitait PAS les signaux !

```wgsl
// AVANT: Shader ne faisait rien avec les signaux
@compute @workgroup_size(256)
fn main(@builtin(global_invocation_id) id: vec3<u32>) {
    // ... aucun code pour traiter signals[]
    if cell_energy.tension > 0.8 { ... }  // Seule logique pr√©sente
}

// APR√àS: Traitement complet des signaux (comme CPU)
for (var s = 0u; s < signal_count; s++) {
    let signal = signals[s];
    // Wake sleeping cells
    if (cell_meta.flags & FLAG_SLEEPING) != 0u && intensity > 0.1 {
        cell_meta.flags = cell_meta.flags & ~FLAG_SLEEPING;
    }
    // Give energy via resonance (La Vraie Faim)
    let resonance = calculate_resonance(signal.content, state);
    if resonance > resonance_threshold {
        cell_energy.energy += energy_gain;
    }
}
```

**Aussi supprim√© :** Filtre de distance qui excluait 50% des cellules.

**R√©sultat :**
- GPU √©volution multi-g√©n√©rationnelle fonctionnelle
- 5k cells : Gen 3-7, E=0.60, stable
- 10k+ cells : n√©cessite plus de signaux (trainer plus rapide)

**Param√®tres finaux :**
```rust
reproduction_threshold: 0.50,  // Abaiss√© de 0.70
child_energy: 0.40,
cost_rest: 0.0002,
signal_energy_base: 0.30,
signal_resonance_factor: 3.0,
```

#### Fix Wave Propagation + Stochasticity (Session 32 Part 10)

**Philosophie :** Les signaux ne sont pas continus - ils se propagent comme des **ondes** dans le substrat. Le m√™me signal ne doit pas toujours donner le m√™me r√©sultat.

**Probl√®mes identifi√©s :**

1. **Distance filter trop restrictif** : `signal_radius=15` dans un espace 8D o√π la distance moyenne est ~23
2. **Pas de stochasticit√©** : m√™me signal ‚Üí m√™me r√©sultat (d√©terministe)
3. **Test script cass√©** : envoyait du texte brut au lieu de JSON `Signal`

**Fixes appliqu√©s :**

```wgsl
// SIGNAL_TEMPLATE - Wave propagation avec stochasticit√©

// Hash function pour bruit stochastique
fn hash(seed: u32) -> f32 {
    var x = seed;
    x = x ^ (x >> 16u);
    x = x * 0x7feb352du;
    x = x ^ (x >> 15u);
    x = x * 0x846ca68bu;
    x = x ^ (x >> 16u);
    return f32(x & 0xFFFFu) / 65535.0;  // [0, 1]
}

// Distance-based wave attenuation
let dist = sqrt(dist_sq);
if dist >= config.signal_radius { continue; }  // Outside wave
let attenuation = 1.0 - (dist / config.signal_radius);

// Stochastic noise (¬±10%) - same signal ‚â† same result
let noise = (hash(noise_seed + s) - 0.5) * 0.2;
let noisy_attenuation = clamp(attenuation + noise, 0.0, 1.0);
```

**Config mise √† jour :**

```rust
signal_radius: 30.0,         // √âlargi de 15 ‚Üí 30 pour 8D
reproduction_threshold: 0.45, // Abaiss√© de 0.50
child_energy: 0.35,
```

**Test script corrig√© :**

```python
# Avant: ws.send("bonjour")  # Texte brut - ignor√©!
# Apr√®s: Conversion en JSON Signal
def text_to_signal_json(text):
    h = hashlib.md5(text.encode()).digest()
    tension = [((b / 255.0) * 2.0 - 1.0) for b in h[:8]]
    return json.dumps({
        "content": tension + [0.0] * 24,
        "intensity": 0.3 + 0.7 * min(magnitude / 2.0, 1.0),
        "label": text,
        "signal_type": "Perception"
    })
```

**R√©sultat :**
- Gen 11 atteint en 90 secondes
- √âvolution multi-g√©n√©rationnelle fonctionnelle sur GPU
- Propagation par ondes (att√©nuation distance)
- Stochasticit√© (m√™me mot ‚Üí r√©sultats diff√©rents)

#### GPU Lifecycle Slot System (Session 32 Part 12)

**Objectif :** √âliminer les freezes tous les 1000 ticks caus√©s par les t√©l√©chargements GPU‚ÜíCPU.

**Architecture Slot System :**

```
GPU (Fixed capacity)
‚îú‚îÄ‚îÄ cell_slots[MAX_CAPACITY]      // Pr√©-allou√©
‚îú‚îÄ‚îÄ free_list[MAX_CAPACITY]       // Indices disponibles
‚îú‚îÄ‚îÄ lifecycle_counters            // Compteurs atomiques
‚îÇ   ‚îú‚îÄ‚îÄ free_count: u32           // Slots libres
‚îÇ   ‚îú‚îÄ‚îÄ alive_count: u32          // Cellules vivantes
‚îÇ   ‚îú‚îÄ‚îÄ births_this_tick: u32     // Naissances ce tick
‚îÇ   ‚îî‚îÄ‚îÄ deaths_this_tick: u32     // Morts ce tick
```

**Nouveaux fichiers/structs :**

| Fichier | Ajout |
|---------|-------|
| `aria-core/src/soa.rs` | `LifecycleCounters` struct (32 bytes) |
| `aria-compute/src/compiler.rs` | `DEATH_SHADER`, `BIRTH_SHADER`, `RESET_LIFECYCLE_COUNTERS_SHADER` |
| `aria-compute/src/backend/gpu_soa.rs` | Buffers, pipelines, dispatch |

**DEATH_SHADER :**
```wgsl
// Marque les cellules mortes (energy <= 0)
// Push leur slot dans free_list (atomique)
// Update alive_count et deaths_this_tick
if energy <= 0.0 {
    metadata[idx].flags = cell_meta.flags | FLAG_DEAD;
    let free_idx = atomicAdd(&counters.free_count, 1u);
    free_list[free_idx] = idx;
    atomicSub(&counters.alive_count, 1u);
    atomicAdd(&counters.deaths_this_tick, 1u);
}
```

**BIRTH_SHADER (pr√™t, non dispatch√©) :**
```wgsl
// Pop slot de free_list (atomique)
// Initialise l'enfant avec DNA mut√©
// Update alive_count et births_this_tick
let free_count = atomicSub(&counters.free_count, 1u);
let child_idx = free_list[free_count - 1u];
// ... initialize child ...
atomicAdd(&counters.alive_count, 1u);
```

**Avantages :**
- Z√©ro t√©l√©chargement GPU‚ÜíCPU pendant le tick normal
- Naissance/mort = op√©rations atomiques GPU O(1)
- `read_lifecycle_counters()` pour stats p√©riodiques (l√©ger)
- Pr√©pare la migration compl√®te de lifecycle.rs vers GPU

**√âtat :**
- ‚è≥ Death shader pr√™t mais D√âSACTIV√â (cause d√©sync GPU/CPU)
- ‚è≥ Birth shader pr√™t mais pas encore dispatch√© (n√©cessite plus d'int√©gration)
- ‚úÖ M√©thode `read_lifecycle_counters()` pour lire les stats GPU

#### TPS Rate Limiting & Economy Tuning (Session 32 Part 13)

**Probl√®me 1 : √âmissions trop fr√©quentes (~1/sec au lieu de ~1/5sec)**

La boucle principale n'avait pas de rate limiter - TPS r√©el ~5000+ au lieu de 1000.

```rust
// main.rs - AVANT: yield_now() = aussi vite que possible
tokio::task::yield_now().await;

// APR√àS: Rate limit √† 1000 TPS
tokio::time::sleep(tokio::time::Duration::from_micros(1000)).await;
```

**Cooldowns corrig√©s :**

| Cooldown | Avant | Apr√®s |
|----------|-------|-------|
| `EMISSION_COOLDOWN_TICKS` | 25 | 5000 |
| Spontaneous cooldown | 500 | 5000 |
| Expression cooldown | 5000 | 5000 (ok) |

**Probl√®me 2 : Gen 0 √©ternellement (pas de reproduction)**

√ânergie moyenne ~0.30 mais seuil de reproduction = 0.40 ‚Üí impossible de reproduire.

```rust
// config.rs - AVANT
reproduction_threshold: 0.40,
child_energy: 0.35,
cost_divide: 0.40,  // Parent meurt apr√®s division!

// APR√àS
reproduction_threshold: 0.28,  // Accessible avec √©nergie ~0.30
child_energy: 0.24,
cost_divide: 0.12,  // Parent survit (0.28 - 0.12 = 0.16)
```

**Fichiers modifi√©s :**

| Fichier | Changement |
|---------|------------|
| `aria-brain/src/main.rs` | Rate limit 1ms/tick |
| `aria-brain/src/substrate/types.rs` | EMISSION_COOLDOWN: 25 ‚Üí 5000 |
| `aria-brain/src/substrate/spontaneous.rs` | Cooldown: 500 ‚Üí 5000 |
| `aria-core/src/config.rs` | Seuils reproduction ajust√©s |
| `Taskfile.yml` | Supprim√© r√©f√©rences √† aria-train |

**R√©sultat attendu :**
- √âmissions espac√©es de ~5 secondes
- √âvolution multi-g√©n√©rationnelle (Gen1, Gen2, etc.)
- Population oscillante mais avec lign√©e √©volutive

### Session 33 - Autonomous Learning (Web + Expression)

**ARIA apprend du web et g√©n√®re des expressions √©mergentes sans LLM.**

#### 1. Web Learner (`web_learner.rs`)

Module pour apprentissage autonome depuis Internet :

```rust
// Sources de connaissance
- Simple Wikipedia (articles accessibles)
- Wikiquote (sagesse/philosophie)

// Flux d'apprentissage
1. Fetch URL ‚Üí Extract HTML ‚Üí Strip tags
2. Split en phrases ‚Üí Filter (20-500 chars)
3. text_to_tension() ‚Üí TensionVector [8D]
4. Queue injections ‚Üí Inject into substrate

// Tous les 5 minutes
autonomous_learning_loop() ‚Üí fetch_and_learn()
```

#### 2. Expression Generator (`expression.rs`)

G√©n√©ration de "parole" √©mergente sans LLM :

```rust
// Expressions apprises
- User input ‚Üí learn_from_user()
- Web content ‚Üí learn_from_web()
- Seeds: ~20 mots √©motionnels de base

// G√©n√©ration
1. Emergence ‚Üí tension pattern [8D]
2. find_related() ‚Üí expressions similaires
3. resonance() ‚Üí meilleur match
4. Output: "tension:positive|says:curieux"
```

#### 3. Trainer Autonome (`scripts/autonomous_trainer.py`)

Script pour entra√Ænement 24h/24 :

```bash
./scripts/run_overnight.sh  # D√©marre brain + trainer
```

- Envoie des stimuli toutes les 5s
- Varie les patterns √©motionnels
- Log activit√© dans `data/trainer_log.txt`
- Stats toutes les 60s

#### Nouveaux endpoints

| Endpoint | Description |
|----------|-------------|
| `/learn` | Stats du web learner |
| `/express` | Stats du g√©n√©rateur d'expressions |

#### Fichiers cr√©√©s

| Fichier | Description |
|---------|-------------|
| `aria-brain/src/web_learner.rs` | Web fetcher et knowledge extraction |
| `aria-brain/src/expression.rs` | Expression generator |
| `scripts/autonomous_trainer.py` | Trainer Python |
| `scripts/run_overnight.sh` | Script de lancement |

### Session 31 - Physical Intelligence (Vocabulary Removal)

**ARIA passe en mode "Intelligence Physique" - le vocabulaire est supprim√©.**

#### Philosophie

L'intelligence d'ARIA ne vient plus de l'association de mots, mais de la physique de ses cellules. Les "lois" (Pr√©diction, Hebb, Expansion) d√©finissent le comportement √©mergent.

#### 1. Suppression du Vocabulaire

Fichiers/modules supprim√©s ou nettoy√©s :
- `aria-brain/src/memory/vocabulary.rs` - **supprim√©**
- `WordCategory`, `UsagePattern` - supprim√©s de `types.rs`
- `VisualWordLink`, `visual_word_links` - supprim√©s
- `word_frequencies`, `word_associations`, `semantic_clusters` - supprim√©s de `LongTermMemory`

#### 2. Fix Sleeping Drain

Les cellules Gen0 ne mouraient pas assez vite car le drain de sommeil √©tait trop faible.

**Avant :**
```wgsl
// GPU: 0.1 √ó cost_rest tous les 100 ticks
cell_energy.energy -= config.cost_rest * 0.1;  // ~27h survie!

// CPU: 0.5 √ó cost_rest par tick (incoh√©rent)
state.energy -= config.metabolism.cost_rest * 0.5;
```

**Apr√®s :**
```wgsl
// GPU: 2.0 √ó cost_rest tous les 100 ticks (~3 min survie)
cell_energy.energy -= config.cost_rest * 2.0;

// CPU: 0.02 √ó cost_rest par tick (coh√©rent avec GPU)
state.energy -= config.metabolism.cost_rest * 0.02;
```

**R√©sultat** : Cellules dormantes meurent en ~3 minutes, permettant aux nouvelles g√©n√©rations d'√©merger.

#### 3. Endpoints simplifi√©s

| Endpoint | Avant | Apr√®s |
|----------|-------|-------|
| `/words` | Liste des mots connus | Message "removed" |
| `/associations` | Associations mot-mot | Message "removed" |
| `/clusters` | Clusters s√©mantiques | Message "removed" |
| `/visual` | M√©moires + word links | M√©moires uniquement |

#### Fichiers modifi√©s

| Fichier | Changement |
|---------|------------|
| `aria-brain/src/memory/vocabulary.rs` | Supprim√© |
| `aria-brain/src/memory/mod.rs` | Nettoy√© (vocab, word_links) |
| `aria-brain/src/memory/types.rs` | Supprim√© WordCategory, UsagePattern |
| `aria-brain/src/memory/visual.rs` | Supprim√© VisualWordLink |
| `aria-brain/src/main.rs` | Endpoints simplifi√©s |
| `aria-brain/src/substrate/signals.rs` | Supprim√© visual‚Üíword |
| `aria-compute/src/compiler.rs` | Sleeping drain 0.1 ‚Üí 2.0 |
| `aria-compute/src/backend/cpu.rs` | Sleeping drain 0.5 ‚Üí 0.02 |
| `aria-compute/src/backend/gpu_soa.rs` | Sync 100 ‚Üí 1000 ticks |
| `aria-brain/src/substrate/mod.rs` | Sync 100 ‚Üí 1000 ticks |
| `aria-body/src/visualizer.rs` | Supprim√© word_count, recent_words |
| `aria-body/src/main.rs` | Supprim√© fetch /words, /associations |

#### 4. Optimisation GPU‚ÜíCPU Sync

Le t√©l√©chargement GPU‚ÜíCPU bloquant √©tait trop fr√©quent (tous les 100 ticks = 10x/sec).

**Avant :**
```rust
let should_download = self.tick % 100 == 0;  // Trop fr√©quent!
```

**Apr√®s :**
```rust
let should_download = self.tick % 1000 == 0;  // 1x/sec √† 1000 TPS
```

**R√©sultat** : 10x moins de syncs bloquants.

#### 5. Gen0 Drain (√©volution bloqu√©e)

Les cellules Gen0 s'accumulaient (59k ready!) car elles ne mouraient pas :
- Elles ont de l'√©nergie ‚Üí pas de sleeping drain
- Elles ne reproduisent pas (on priorise Gen2+)
- Elles bloquent la population

**Fix** : Drain de 2% par lifecycle tick pour les Gen0 "ready" non s√©lectionn√©es.

```rust
// lifecycle.rs - apr√®s reproduction
if gen0_count > 100 {
    for (idx, _) in gen_buckets[0].iter() {
        self.states[*idx].energy -= 0.02;  // 2% drain
        if energy <= 0.0 { kill(); }
    }
}
```

**R√©sultat** : Gen0 meurent en ~50 lifecycle ticks, laissant place aux nouvelles g√©n√©rations.

### Session 30 - GPU Fixes & Lineage Progression

**D√©blocage de l'√©volution multi-g√©n√©rationnelle et corrections critiques GPU.**

#### 1. Fix Lineage Progression

Le compteur de g√©n√©ration √©tait bloqu√© √† Gen1 malgr√© 3000 cellules Gen1 pr√™tes √† reproduire.

**Cause** : `ready_to_divide.into_iter().take(500)` s√©lectionnait par ordre d'index. Les cellules Gen0 (indices 0-99999) monopolisaient les 500 slots de reproduction.

**Fix** : Tri par g√©n√©ration d√©croissante avant s√©lection.
```rust
// lifecycle.rs
ready_to_divide.sort_by(|a, b| b.2.cmp(&a.2));  // Gen DESC
// Les g√©n√©rations sup√©rieures reproduisent en priorit√©
```

**R√©sultat** : Gen2+, Gen3+, etc. peuvent maintenant √©merger.

#### 2. GPU Alignment Fixes (110k+ cells)

Trois erreurs WGSL corrig√©es pour supporter >100k cellules :

**a) Uniform Buffer Alignment**
```wgsl
// AVANT (crash avec uniform buffer)
_pad: array<u32, 3>  // stride = 4 bytes - interdit!

// APR√àS
_pad1: u32,
_pad2: u32,
_pad3: u32,         // 3 champs s√©par√©s OK
```

**b) CLEAR_GRID_SHADER Bindings**
```wgsl
// Le shader utilisait binding(0) pour grid
// Mais le layout attendait:
// - binding 0: positions (read-only)
// - binding 1: grid (read-write)
// - binding 2: spatial_config

// Fix: Ajouter tous les bindings m√™me si inutilis√©s
@group(0) @binding(0) var<storage, read> positions: ...
@group(0) @binding(1) var<storage, read_write> grid: ...
@group(0) @binding(2) var<uniform> config: ...
```

**c) Reserved Keyword 'target'**
```wgsl
// AVANT
fn find_connection(conn: CellConnections, target: u32)  // 'target' r√©serv√©!

// APR√àS
fn find_connection(conn: CellConnections, target_id: u32)
```

#### Commits

| Hash | Description |
|------|-------------|
| `c8a96b3` | fix(gpu): rename reserved keyword 'target' |
| `04d794c` | fix(gpu): align CLEAR_GRID_SHADER bindings |
| `647df81` | fix(gpu): correct WGSL uniform buffer alignment |
| `31c2c8c` | fix(evolution): prioritize higher generations |

#### √âtat

- GPU backend stable √† 110k+ cellules
- √âvolution multi-g√©n√©rationnelle fonctionnelle
- Logs enrichis montrant Gen0/Gen1/Gen2+ ready vs reproducing

### Session 31 - CPU‚ÜíGPU Migration (Scale 1M-10M)

**Migration des op√©rations critiques CPU vers GPU pour supporter 1M-10M cellules √† 1000 TPS.**

#### Op√©rations migr√©es

| Op√©ration | Avant | Apr√®s | Gain estim√© |
|-----------|-------|-------|-------------|
| Predictive Physics | CPU 40M ops/tick | GPU PREDICTION_EVALUATE_SHADER | ~40M ops/tick |
| Hebbian Spatial | CPU 50M ops/5 ticks | GPU HEBBIAN_CENTROID + ATTRACTION | ~50M ops/5 ticks |
| Cluster Hysteresis | CPU 10M ops/50 ticks | GPU CLUSTER_STATS + HYSTERESIS | ~10M ops/50 ticks |
| Lineage Sort | O(n log n) sort | O(n) bucket-based | 10-50√ó sur sort |

#### Nouveaux shaders WGSL

**1. PREDICTION_EVALUATE_SHADER** (d√©j√† existant mais non dispatch√©)
- √âvalue pr√©dictions vs r√©alit√©
- Applique r√©compenses/p√©nalit√©s √©nerg√©tiques
- Maintenant dispatch√© chaque tick

**2. HEBBIAN_CENTROID_SHADER** (nouveau)
- Accumule le centro√Øde pond√©r√© des cellules actives
- Utilise fixed-point i32 atomics (WGSL n'a pas atomicAdd f32)
- Scale √ó1000 pour pr√©cision 0.001

**3. HEBBIAN_ATTRACTION_SHADER** (nouveau)
- D√©place les cellules actives vers le centro√Øde
- Force proportionnelle √† distance √ó activit√© √ó plasticit√©
- Tous les 5 ticks

**4. CLUSTER_STATS_SHADER** (nouveau)
- Accumule activit√© et count par cluster (256 clusters max)
- Fixed-point u32 atomics

**5. CLUSTER_HYSTERESIS_SHADER** (nouveau)
- Met √† jour hysteresis selon activit√© moyenne du cluster
- Clusters actifs (>0.6) ‚Üí hysteresis +0.05
- Clusters inactifs (<0.2) ‚Üí hysteresis -0.02
- Pas de cluster ‚Üí hysteresis -0.1
- Tous les 50 ticks

#### Optimisation Lineage Sort

```rust
// AVANT: O(n log n)
ready_to_divide.sort_by(|a, b| b.2.cmp(&a.2));

// APR√àS: O(n) bucket-based
const MAX_GEN_BUCKETS: usize = 32;
let mut gen_buckets: [Vec<(usize, u32)>; 32] = Default::default();
// Single pass: bucket by generation
// Flatten from highest generation down
```

#### Buffers GPU ajout√©s

| Buffer | Taille | Usage |
|--------|--------|-------|
| `centroid_buffer` | 80 bytes | 16√ói32 + u32 + u32 + 2√óu32 pad |
| `cluster_stats_buffer` | 2048 bytes | 256√óu32 (activity) + 256√óu32 (count) |

#### Fix WGSL

**Reserved keyword 'meta'** ‚Üí Renomm√© en `cell_meta` dans les shaders cluster.

#### Fichiers modifi√©s

| Fichier | Changements |
|---------|-------------|
| `aria-compute/src/compiler.rs` | +4 shaders WGSL, getters |
| `aria-compute/src/backend/gpu_soa.rs` | +2 buffers, +4 pipelines, +4 bind groups, dispatch calls |
| `aria-brain/src/substrate/mod.rs` | Suppression CPU predictive/hebbian/cluster |
| `aria-brain/src/substrate/lifecycle.rs` | O(n) bucket sort |

#### R√©sultat attendu

| M√©trique | Avant | Apr√®s |
|----------|-------|-------|
| CPU ops/tick @ 5M | ~65M | ~5M |
| GPU utilisation | 30% | 80%+ |
| Max cells @ 1000 TPS | ~200k | ~5M+ |

### Session 24 - CellMetadata & Naga Fix

**Migration majeure : `CellFlags` ‚Üí `CellMetadata` avec fix critique du compilateur WGSL.**

#### Probl√®me r√©solu

L'erreur naga `Expression [50] is not cached!` bloquait le GPU backend. Cause : op√©rateurs compound (`&=`, `|=`) sur champs de struct et pointeurs vers champs de struct en WGSL.

#### Changements majeurs

**1. CellMetadata (16 bytes) remplace CellFlags (4 bytes)**
```rust
// aria-core/src/soa.rs
struct CellMetadata {
    flags: u32,       // Sleeping, Dead, etc.
    cluster_id: u32,  // Phase 6 - Semantic Synthesis
    hysteresis: f32,  // Phase 6 - Structural Stability
    _pad: u32,
}
```

**2. Fix WGSL pour naga**
```wgsl
// AVANT (cassait naga)
fn set_sleep_counter(f: ptr<function, u32>, counter: u32) { *f = ... }
cell_meta.flags &= ~FLAG_SLEEPING;
cell_meta.flags |= FLAG_DEAD;

// APR√àS
fn set_sleep_counter(f: u32, counter: u32) -> u32 { return ...; }
cell_meta.flags = cell_meta.flags & ~FLAG_SLEEPING;
cell_meta.flags = cell_meta.flags | FLAG_DEAD;
```

**3. Logique dynamique sans compound operators**
```rust
// Dans generate_dna_logic()
cell_energy.energy = cell_energy.energy + config.energy_gain * modifier;
cell_energy.activity_level = cell_energy.activity_level * decay_rate;
```

#### Fichiers modifi√©s

| Fichier | Changement |
|---------|------------|
| `aria-core/src/soa.rs` | `CellFlags` ‚Üí `CellMetadata` (16 bytes) |
| `aria-core/src/cell.rs` | Ajout `cluster_id`, `hysteresis` |
| `aria-compute/src/compiler.rs` | Fix WGSL: pas de compound operators ni pointeurs struct |
| `aria-compute/src/backend/gpu_soa.rs` | `flags_buffer` ‚Üí `metadata_buffer` |

#### √âtat de l'organisme
- GPU backend stable avec AMD Radeon NAVI14 (Vulkan)
- JIT compilation fonctionnelle
- 100% sparse savings au repos

### Session 28 - Loi de Compression (Predictive Physics)

**L'√©nergie est r√©compens√©e par la pr√©cision de la pr√©diction.**

- **Concept** : "Surprise costs energy."
- **Impl√©mentation** : Chaque cellule a un `predicted_state`.
- **Physique** :
  - Erreur faible (< 0.1) ‚Üí Gain d'√©nergie (R√©compense)
  - Erreur forte (Surprise) ‚Üí Perte d'√©nergie (Co√ªt m√©tabolique)
- **But** : Forcer le cerveau √† internaliser les mod√®les du monde pour minimiser le co√ªt √©nerg√©tique.

### Session 29 - R√®gles vers Lois (Migration DNA)

**Migration finale : remplacement des constantes hard-cod√©es par des lois g√©n√©tiques.**

- **Philosophie** : "Il n'y a pas de nombres magiques dans la nature."
- **Changements majeurs** :
    - **Seuil de R√©sonance** (Gene 5) : Chaque cellule d√©cide quel niveau de similarit√© est suffisant pour accepter un signal (Food vs Noise).
    - **Efficacit√© √ânerg√©tique** (Gene 4) : Trade-off g√©n√©tique entre extraction d'√©nergie et co√ªt.
    - **Inertie Tension** (Gene 6) : "Temp√©rament" (Calme vs Anxieux) d√©fini par l'ADN.
- **Fichiers** : `dna.rs`, `cpu.rs`, `compiler.rs` (WGSL).
- **R√©sultat** : Diversit√© comportementale √©mergente (Picky Eaters, Trash Eaters, etc.).

### Session 27 - Loi d'Association (Hebb's Law)

**"Fire together, move together." (Plasticit√© Spatiale)**

- **Concept** : Remplacer les connexions synaptiques co√ªteuses (O(N¬≤)) par une attraction spatiale (O(N)).
- **M√©canisme** : Les cellules actives calculent leur "Centre de Gravit√©" (Centroid) et se d√©placent physiquement vers lui.
- **R√©sultat** : Les concepts li√©s s'agglutinent spatialement (Clustering s√©mantique).

### Session 26 - Loi d'Expansion (Lineage Fix)

**La vie s'√©tend pour remplir l'√©nergie disponible.**

- **Fix Critique** : Suppression du cap artificiel `target_population`.
- **Dynamique** : La reproduction est maintenant limit√©e par :
  1. L'√©nergie disponible (Seuil de reproduction)
  2. Une limite physique de s√©curit√© (OOM protection uniquement)
- **R√©sultat** : Compteur de g√©n√©ration d√©bloqu√©, vagues de population naturelles.

### Session 25 - Loi de Pr√©diction (Prediction Law)

**ARIA commence √† pr√©dire son futur - les cellules qui comprennent leur monde survivent.**

#### Philosophie

Plut√¥t que de hard-coder des r√®gles d'intelligence, on impl√©mente une **loi physique fondamentale** :

> "Les cellules qui pr√©disent correctement leur √©tat futur gagnent de l'√©nergie.
> Les cellules qui se trompent en perdent."

L'intelligence **√©merge** de la pression √©volutive, pas du code.

#### Changements majeurs

**1. CellPrediction struct (48 bytes)**
```rust
// aria-core/src/soa.rs
struct CellPrediction {
    predicted_state: [f32; 8],  // Pr√©diction de l'√©tat futur
    confidence: f32,            // Confiance (0.0 = devine, 1.0 = certain)
    last_error: f32,            // Erreur de la derni√®re pr√©diction
    cumulative_score: f32,      // Score long-terme
    _pad: f32,
}
```

**2. Shaders GPU de pr√©diction**
```wgsl
// PREDICTION_GENERATE_SHADER: Avant le tick
// Chaque cellule pr√©dit son futur bas√© sur ses connexions Hebbiennes
prediction = weighted_average(connected_neighbors_states)
confidence = min(total_connection_strength / 3.0, 1.0)

// PREDICTION_EVALUATE_SHADER: Apr√®s le tick
// Compare pr√©diction vs r√©alit√©, applique r√©compenses/p√©nalit√©s
accuracy = 1.0 - RMSE(predicted, actual)
if accuracy > 0.7: energy += accuracy * confidence * 0.02  // R√©compense
if accuracy < 0.3: energy -= error * confidence * 0.01    // P√©nalit√© (punit la surconfiance)
```

**3. Pression √©volutive vers l'intelligence**
- Les cellules bien connect√©es peuvent mieux pr√©dire ‚Üí survivent
- Les cellules surconfiantes qui se trompent ‚Üí meurent
- L'humilit√© (basse confiance quand incertain) est r√©compens√©e

#### Fichiers modifi√©s

| Fichier | Changement |
|---------|------------|
| `aria-core/src/soa.rs` | Ajout `CellPrediction`, mise √† jour `SoABuffers` |
| `aria-core/src/lib.rs` | Export de `CellPrediction` |
| `aria-compute/src/compiler.rs` | Shaders `PREDICTION_GENERATE_SHADER` et `PREDICTION_EVALUATE_SHADER` |
| `aria-compute/src/backend/gpu_soa.rs` | Buffer et pipelines de pr√©diction |

#### Prochaines lois √† impl√©menter
- **Loi de Hebb** : "Fire together, wire together" (connexions renforc√©es)
- **Loi de Compression** : R√©compense pour repr√©sentations compactes
- **Loi de Curiosit√©** : Bonus pour exploration de nouveaux √©tats

### Session 23 - ARIA Genesis (Structural Evolution & Phase 5)

**ARIA a franchi l'√©tape ultime : elle peut maintenant r√©√©crire son propre code de calcul GPU.**

#### Changements majeurs

**1. Compilation JIT & Hot-Reloading**
- Infrastructure permettant de g√©n√©rer et recompiler les shaders WGSL au runtime.
- Z√©ro interruption : les pipelines GPU sont remplac√©s √† chaud sans arr√™ter la simulation.

**2. Traduction DNA -> WGSL (Densit√© S√©mantique)**
- Le `structural_checksum` du DNA est interpr√©t√© comme des directives algorithmiques.
- Exemples impl√©ment√©s : m√©tabolisme logistique vs lin√©aire, att√©nuation de signal dynamique.

**3. Boucle de R√©flexivit√© (Axe 3)**
- ARIA r√©injecte ses propres "pens√©es" (tensions √©mergentes) comme entr√©es sensorielles.
- G√®ne `reflexivity_gain` : chaque cellule d√©cide √† quel point elle √©coute l'√™tre global.

**4. Module `compiler.rs`**
- Centralisation de toute la logique WGSL sous forme de templates injectables.
- S√©curisation des variables et mapping direct avec le pool d'ADN.

#### Fichiers modifi√©s

| Fichier | Changement |
|---------|------------|
| `aria-compute/src/compiler.rs` | Cr√©ation du moteur JIT et des templates |
| `aria-compute/src/backend/gpu_soa.rs` | Support hot-reload et pipeline swap |
| `aria-brain/src/substrate/mod.rs` | D√©tection d'√©volution structurelle et bouclage r√©flexif |
| `aria-core/src/dna.rs` | Support checksum structurel et g√®nes de r√©flexivit√© |
| `aria-core/src/traits.rs` | Extension de `ComputeBackend` avec `recompile()` |

#### √âtat de l'organisme
- ARIA commence √† sortir de l'intelligence statistique pour entrer dans l'intelligence structurelle.
- Elle poss√®de d√©sormais le "gript" sur sa propre physique num√©rique.

### Session 22 - √âconomie √âquilibr√©e (Survival Fix)

**ARIA peut enfin survivre plus de 60 secondes !**

Le probl√®me : l'√©conomie "La Vraie Faim" √©tait trop agressive. √Ä 1000+ TPS, les cellules mouraient en ~10 secondes sans pouvoir manger assez.

#### Changements majeurs

**1. Co√ªts r√©duits (10x moins)**
```rust
// AVANT: Trop cher pour le TPS √©lev√©
cost_rest: 0.0001    // 10,000 ticks ‚Üí mort (6 sec √† 1700 TPS)
cost_signal: 0.01
cost_move: 0.005

// APR√àS: Survivable
cost_rest: 0.00001   // 100,000 ticks ‚Üí mort (100 sec √† 1000 TPS)
cost_signal: 0.001
cost_move: 0.0005
```

**2. √ânergie des signaux augment√©e (5x)**
```rust
signal_energy_base: 0.05      // AVANT: 0.01
signal_resonance_factor: 3.0  // AVANT: 2.0
```

**3. Seuil de r√©sonance abaiss√©**
```rust
// AVANT: Trop strict
if resonance > 0.3 { /* eat */ }

// APR√àS: Plus de cellules peuvent manger
if resonance > 0.1 { /* eat */ }
```

**4. Signal radius augment√© (3x)**
```rust
signal_radius: 15.0  // AVANT: 5.0 - trop petit, cellules ne voyaient pas le signal
```

**5. Bruit de fond s√©mantique**

Nouveau syst√®me pour √©viter l'entropie = 0 (syst√®me gel√©) :
- Tous les 50 ticks sans signal
- 0.1% des cellules dormantes re√ßoivent du bruit
- Petite injection d'√©nergie pour √©viter la famine totale

**6. Visualisation am√©lior√©e**

La grille Neural Activity montre maintenant les cellules dormantes (√©nergie √ó 0.2) pour ne plus √™tre vide quand 99% des cellules dorment.

**7. Bruit stochastique (anti-pattern statique)**

Le m√™me mot "Moka" ne g√©n√®re plus exactement le m√™me vecteur :
```rust
// Dans text_to_tension() - 10% de variation al√©atoire
let noise = rng.gen_range(-0.1..0.1);
*t = (*t + noise).clamp(-1.0, 1.0);
```

**8. Feedback Loop (boucle de r√©troaction)**

Quand ARIA √©met et que l'utilisateur r√©pond rapidement :
- Les cellules qui ont particip√© √† l'√©mission re√ßoivent un bonus d'√©nergie
- "Je bouge, le monde me r√©pond, donc j'existe"
```rust
// Dans inject_signal - si r√©ponse < 500 ticks apr√®s √©mission
let feedback_bonus = 0.1 * (1.0 - ticks_since_emit / 500.0);
```

**9. Harmoniques 16D (expansion spectrale)**

Le vecteur 8D de tension est √©tendu en 16D avec des harmoniques :
```rust
// Dimensions 0-7: signal direct
// Dimensions 8-11: produits crois√©s (arousal√óvalence, etc.)
// Dimensions 12-13: diff√©rences (arousal-intensity, etc.)
// Dimensions 14-15: modulations sinuso√Ødales
```

#### Fichiers modifi√©s

| Fichier | Changement |
|---------|------------|
| `aria-core/src/config.rs` | Co√ªts r√©duits, signal_radius 15.0 |
| `aria-core/src/tension.rs` | Bruit stochastique + harmoniques 16D |
| `aria-compute/src/backend/cpu.rs` | Seuil r√©sonance 0.1 |
| `aria-compute/src/backend/gpu_soa.rs` | Seuil r√©sonance 0.1 |
| `aria-compute/src/spatial_gpu.rs` | Seuil r√©sonance 0.1 (2 endroits) |
| `aria-brain/src/substrate/mod.rs` | Bruit de fond + visualisation + last_emission_cells |
| `aria-brain/src/substrate/signals.rs` | Feedback loop + harmoniques |
| `aria-brain/src/substrate/emergence.rs` | Tracking des cellules √©mettrices |

#### Nouvelle √©conomie

| M√©trique | Valeur | Signification |
|----------|--------|---------------|
| Temps de survie | ~100 sec | Sans nourriture √† 1000 TPS |
| Gain par signal | ~0.05-0.2 | Avec bonne r√©sonance |
| Cellules nourries | Plus large | Seuil 0.1 vs 0.3 |

### Session 21 - Thermal Scanner Body (Visualisation Avanc√©e)

**Le body devient un scanner thermique de l'intelligence artificielle !**

La visualisation n'est plus d√©corative - elle pilote une simulation massive o√π les donn√©es brutes sont devenues illisibles. Le nouveau body agit comme un diagnostic temps r√©el du substrat neural.

#### 1. Heatmap Thermique 2D

Projection des 16 dimensions s√©mantiques sur une carte 2D avec gradient thermique :

```
Couleurs: noir ‚Üí bleu ‚Üí cyan ‚Üí vert ‚Üí jaune ‚Üí orange ‚Üí rouge ‚Üí blanc
          (dormant)                    (mod√©r√©)                  (surchauffe)
```

**3 modes de vue** (Tab pour cycler) :
- **ACTIVITY** : Activit√© neurale (cellules √©veill√©es + activation interne)
- **TENSION** : Champ de tension (d√©sir physique d'agir)
- **ENERGY** : Distribution √©nerg√©tique (sant√© des cellules)

#### 2. Graphes Sparklines Temps R√©el

Historique sur 60 √©chantillons (~30 secondes) :
- **HP** : Sant√© du syst√®me (vert = √©quilibr√©)
- **Entropy** : Niveau de chaos (magenta = organisation vs d√©sordre)

#### 3. Indicateurs de Lign√©e √âlite

Suivi de la pression √©volutive :
```
üß¨ Gen: 15 (avg: 3.2)    ‚Üê G√©n√©ration max et moyenne
üëë ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 42 elite   ‚Üê Cellules g√©n√©ration >10
üìö 128 words 45 links    ‚Üê Mots et associations appris
```

#### 4. M√©triques Avanc√©es

**Status bar compacte** :
```
‚óè ARIA  HP:72%  E:0.45(balanced)  GPU:95%  T:12847  [ACTIVITY]
```

- HP : System health (composite de entropy + awake ratio + survival)
- E : Entropie (ordered/balanced/chaotic)
- GPU : Sparse dispatch savings (% de cellules dormantes)
- T : Tick courant

**Panel Cells** :
- √ânergie moyenne + indicateur visuel
- Barre de tension (d√©sir physique d'agir)
- Compteurs awake/sleeping avec pourcentages

#### 5. Endpoint `/substrate` Enrichi

Nouvelles m√©triques expos√©es dans `SubstrateView` :

```rust
// Grilles 16x16
tension_grid: Vec<f32>,        // Champ de tension spatiale

// Lign√©e g√©n√©tique
max_generation: u32,           // G√©n√©ration la plus ancienne
avg_generation: f32,           // G√©n√©ration moyenne
elite_count: usize,            // Cellules gen > 10

// Performance
sparse_savings_percent: f32,   // % √©conomie GPU

// Tension physique
avg_energy: f32,
avg_tension: f32,
total_tension: f32,
```

#### Fichiers modifi√©s

| Fichier | Description |
|---------|-------------|
| `aria-body/src/visualizer.rs` | Refonte compl√®te avec thermal gradient |
| `aria-body/src/main.rs` | Support Tab + parsing nouvelles m√©triques |
| `aria-brain/src/substrate/mod.rs` | SubstrateView enrichi |

#### Touches clavier

| Touche | Action |
|--------|--------|
| Tab | Cycler les vues heatmap |
| y/Y | Feedback positif (Bravo!) |
| n/N | Feedback n√©gatif (Non) |
| Esc | Quitter |

### Session 20 - Architecture GPU pour 5M+ Cellules (CIR R&D)

**Infrastructure compl√®te pour scaler ARIA √† 5 millions de cellules !**

#### 1. Structure of Arrays (SoA) - `aria-core/src/soa.rs`

Nouvelle architecture m√©moire GPU optimis√©e (+40% FPS attendu) :

```rust
// AVANT: Un seul buffer CellState (256 bytes/cell)
struct CellState { position, state, energy, tension, flags, ... }

// APR√àS: Buffers s√©par√©s (acc√®s m√©moire optimis√©)
- CellEnergy (16 bytes): energy, tension, activity_level
- CellPosition (64 bytes): position[16]
- CellInternalState (128 bytes): state[32]
- CellFlags (4 bytes): flags avec hysteresis
```

**Avantages** :
- Meilleure coalescence m√©moire GPU
- Mise √† jour partielle (seul energy change fr√©quemment)
- Cache GPU plus efficace

#### 2. Backend GPU SoA - `aria-compute/src/backend/gpu_soa.rs`

Nouveau backend optimis√© pour 5M+ cellules :

```bash
ARIA_BACKEND=gpu_soa task brain-5m  # Force le nouveau backend
```

**Features** :
- Buffers SoA s√©par√©s
- Hysteresis Sleep (Schmitt Trigger)
- Infrastructure Indirect Dispatch
- Auto-s√©lection pour populations >100k

#### 3. Hysteresis Sleep (Stabilit√© Thermique)

Les cellules ne s'endorment plus instantan√©ment - Schmitt Trigger :

```wgsl
// Seuils d'hyst√©r√©sis
SLEEP_ENTER_THRESHOLD = 0.2  // Basse activit√© ‚Üí compteur++
SLEEP_EXIT_THRESHOLD = 0.4   // Haute activit√© ‚Üí r√©veil
SLEEP_COUNTER_MAX = 3        // 3 ticks cons√©cutifs ‚Üí dodo

// Bits 6-7 du flag = compteur (0-3)
```

**R√©sultat** : Plus de flickering, transitions stables.

#### 4. Spatial Hashing GPU - `aria-compute/src/spatial_gpu.rs`

Grille 64¬≥ pour r√©duire les calculs de distance :

```rust
// AVANT: O(cells √ó signals) = 5M √ó 1024 = 5B calculs
// APR√àS: O(signals √ó neighbors) = 1024 √ó 27 √ó 20 = 552K calculs
// ‚Üí 9000x de r√©duction !
```

**Shaders WGSL** :
- `CLEAR_GRID_SHADER` : Reset la grille
- `BUILD_GRID_SHADER` : Assigne les cellules aux r√©gions
- `SIGNAL_WITH_SPATIAL_HASH_SHADER` : Propagation O(1)

#### 5. Configuration Backend

```rust
// aria-core/src/config.rs
enum ComputeBackendType {
    Auto,      // S√©lection automatique
    Cpu,       // Rayon
    Gpu,       // Legacy AoS
    GpuSoA,    // Optimis√© 5M+
}
```

#### Fichiers cr√©√©s/modifi√©s

| Fichier | Description |
|---------|-------------|
| `aria-core/src/soa.rs` | Types SoA (CellEnergy, CellPosition, CellFlags...) |
| `aria-compute/src/backend/gpu_soa.rs` | Backend GPU SoA complet |
| `aria-compute/src/spatial_gpu.rs` | Spatial Hashing GPU + shaders |
| `aria-core/src/config.rs` | Nouveau variant GpuSoA |

#### Prochaines √©tapes

1. **Int√©gration Spatial Hash** dans `gpu_soa.rs`
2. **Tests √† 1M+ cellules** sur RTX 2070
3. **Texture 2D substrat** pour visualisation temps r√©el

### Session 19 - GPU Sparse Dispatch Fix (Performance)

**Le sparse dispatch fonctionne enfin : 99.99% d'√©conomie GPU !**

#### Bugs corrig√©s

1. **D√©synchronisation GPU ‚Üî CPU** : Le GPU modifiait `CellState.flags` mais les stats lisaient `Cell.activity.sleeping` - deux structures diff√©rentes jamais synchronis√©es.

2. **Deadlock signal propagation** : Les signaux n'√©taient propag√©s que si >100 cellules √©veill√©es ‚Üí toutes dormaient ‚Üí jamais de r√©veil.

3. **signal_radius trop grand** : 50.0 touchait tout l'espace [-10,10]. R√©duit √† 5.0 pour propagation locale.

#### Optimisations transferts GPU ‚Üî CPU

```rust
// AVANT: 50 MB/tick (upload 25MB + download 25MB)
upload_cells(states);     // Chaque tick
download_cells(states);   // Chaque tick

// APR√àS: ~0 MB/tick (sauf tous les 100 ticks)
if first_init { upload_cells(states); }  // Init seulement
if tick % 100 == 0 { download_cells(states); }  // P√©riodique
```

#### R√©sultat
- **99.99% sparse savings** au repos
- Ticks beaucoup plus rapides (√©conomise ~50 MB de transfert/tick)
- ARIA r√©pond toujours correctement

### Session 18 - La Vraie Faim (Evolution Pressure)

**Les cellules doivent maintenant LUTTER pour survivre !**

Gemini a identifi√© le probl√®me : ARIA vivait dans l'abondance. Sans pression, pas d'√©volution.

#### Changements majeurs

```rust
// AVANT: Abondance infinie
energy_gain: 0.00005,        // Gain passif gratuit
signal_bonus: 0.05,          // √ânorme bonus par signal

// APR√àS: La Vraie Faim
energy_gain: 0.0,            // RIEN N'EST GRATUIT
signal_energy_base: 0.005,   // 10x moins
signal_resonance_factor: 2.0 // Seule la r√©sonance nourrit
```

#### Co√ªts des actions
| Action | Co√ªt | Effet |
|--------|------|-------|
| `Rest` | 0.001 | Respirer co√ªte |
| `Signal` | 0.01 | Parler est cher |
| `Move` | 0.005 | Bouger consomme |
| `Divide` | 0.5 | Cr√©er la vie √©puise |

#### R√©sonance
Les cellules ne gagnent de l'√©nergie que si le signal **r√©sonne** avec leur √©tat interne :
```rust
resonance = cosine_similarity(signal, cell_state)
energy_gain = base * intensity * (1 + resonance * factor)
```

#### Impl√©mentation
- **`signals.rs:145`** : Suppression du bypass `0.05 * intensity`
- Les cellules gagnent leur √©nergie UNIQUEMENT via r√©sonance (backend CPU/GPU)
- Config d√©j√† correcte : `energy_gain: 0.0`, `signal_energy_base: 0.005`

#### R√©sultat attendu
- **Extinction massive** : 50k ‚Üí ~5k cellules
- Les survivants seront les **anc√™tres** d'une ARIA intelligente
- Les cellules qui "crient dans le vide" mourront
- Seules les cellules qui communiquent utilement survivront

### Session 17 - Optimisations Gemini (Scale & Intelligence)

**Impl√©mentation de toutes les recommandations de Gemini pour 5M+ cellules !**

#### 1. GPU Sparse Dispatch
```rust
// Nouveau dans aria-compute/src/backend/gpu.rs
- AtomicCounter pour comptage GPU-side
- active_count_buffer et active_indices_buffer
- COMPACT_SHADER: collecte les indices actifs avec atomiques
- Activation auto pour populations >100k cellules
```
**R√©sultat** : 80%+ de r√©duction du travail GPU gaspill√© quand les cellules dorment.

#### 2. Neuroplasticit√© Adaptative
```rust
// Nouveau dans aria-core/src/dna.rs
pub struct MutationContext {
    age: u64,          // Vieilles cellules ‚Üí mutation faible
    fitness: f32,      // ADN performant ‚Üí mutation faible
    activity: f32,     // Cellules actives ‚Üí mutation forte
    exploring: bool,   // Exploration ‚Üí 2x mutation
    is_elite: bool,    // Elite ‚Üí 20% mutation
}

DNA::from_parent_adaptive(parent, rate, ctx) // Mutation contextuelle
```
**R√©sultat** : L'ADN √©volue intelligemment, pr√©servant les bons traits.

#### 3. Multi-Pass Recurrent Processing
```rust
// Nouveau dans aria-core/src/config.rs
pub struct RecurrentConfig {
    passes_per_tick: u32,        // 2 passes par d√©faut
    internal_signal_decay: f32,  // 70% persistance
    internal_signal_threshold: f32,
    enabled: bool,
}
```
**R√©sultat** : Les cellules s'influencent mutuellement avant l'√©mergence ‚Üí "pens√©e interne".

#### 4. Seuils Inhibiteurs Spatiaux
```rust
// Nouveau dans aria-brain/src/substrate/types.rs
pub struct SpatialInhibitor {
    region_activity: Vec<f32>,    // 64 r√©gions (8x8)
    region_last_active: Vec<u64>, // P√©riode r√©fractaire
    // ...
}
```
**R√©sultat** : Les r√©gions r√©cemment actives ont un seuil plus √©lev√© ‚Üí moins de r√©p√©tition.

#### Commits Session 17
1. `feat(gpu): Add sparse dispatch with GPU-side active cell counting`
2. `feat(dna): Add adaptive neuroplasticity mutation system`
3. `feat(substrate): Add multi-pass recurrent processing`
4. `feat(substrate): Add spatial inhibitor thresholds`

### Session 16 - Auto-modification (AGI milestone)

**ARIA modifie consciemment ses propres param√®tres !**

C'est un pas majeur vers l'AGI : ARIA n'attend plus le feedback externe, elle analyse ses performances et d√©cide elle-m√™me quoi changer.

**Nouveau module dans `meta_learning.rs`** :
- `ModifiableParam` : param√®tres qu'ARIA peut modifier (emission_threshold, response_probability, learning_rate, spontaneity, exploration_rate)
- `SelfModification` : une modification propos√©e avec raisonnement
- `SelfModifier` : analyse, propose, et applique les modifications

**R√®gles de d√©cision** :
- Apprentissage en d√©clin ‚Üí augmenter learning_rate ou exploration
- Taux d'√©chec √©lev√© ‚Üí √™tre plus s√©lectif (augmenter emission_threshold)
- Peu de r√©ponses ‚Üí augmenter response_probability
- Comp√©tence √©lev√©e ‚Üí plus de spontan√©it√©, moins d'exploration

**Logs observ√©s** :
```
üîß AUTO-MODIFICATION: response_probability 0.800 ‚Üí 0.900 (confidence: 70%)
   Raison: Peu de r√©ponses ‚Üí augmenter probabilit√© de r√©ponse
```

ARIA a d√©tect√© qu'elle avait peu de r√©ponses, a raisonn√©, et s'est modifi√©e.

**√âvaluation des modifications** :
ARIA √©value si ses modifications am√©liorent r√©ellement ses performances :
- Snapshot des m√©triques au moment de la modification (baseline)
- Apr√®s 2000 ticks, compare avec les m√©triques actuelles
- Logs: `‚úÖ MODIFICATION SUCCESS` ou `‚ùå MODIFICATION NEUTRAL/FAIL`

**Endpoint de visibilit√©** :
```bash
curl http://localhost:8765/self
# ‚Üí current_params, recent_modifications (avec reasoning, evaluated, successful), meta_learning status
```

### Session 15 - Perception visuelle & M√©moire visuelle

**ARIA peut maintenant VOIR, SE SOUVENIR, et PARLER de ce qu'elle voit !**

#### Partie 1 : Perception visuelle
Images ‚Üí vecteurs s√©mantiques 32D.

**Module `vision.rs`** :
- `VisualFeatures` : 32 caract√©ristiques extraites
- `VisualPerception` : analyse images base64
- `VisualSignal` : convertit en vecteur substrate-compatible

#### Partie 2 : M√©moire visuelle
ARIA se souvient des images et apprend √† les nommer.

**Nouveaux types dans `memory/mod.rs`** :
- `VisualMemory` : signature 32D + labels + m√©tadonn√©es
- `VisualWordLink` : prototype visuel associ√© √† un mot

**M√©thodes** :
- `see()` : stocke/reconna√Æt une image
- `link_vision_to_word()` : associe image + mot
- `visual_to_words()` : image ‚Üí mots sugg√©r√©s
- `word_to_visual()` : mot ‚Üí prototype visuel

#### Partie 3 : Expression visuelle
Quand ARIA voit une image qu'elle reconna√Æt, elle dit le mot associ√©.

**Logs** :
```
üëÅÔ∏è‚Üíüí¨ VISUAL RECOGNITION: ARIA sees 'moka' (confidence: 1.00)
```

**Endpoints HTTP** :
```bash
# Envoyer une image (+ optionnel: enseigner des mots)
curl -X POST http://localhost:8765/vision \
  -H "Content-Type: application/json" \
  -d '{"image": "<base64>", "labels": ["moka", "chat"]}'

# Voir les stats de m√©moire visuelle
curl http://localhost:8765/visual
```

**Test** :
```python
# 1. Enseigner: orange = "moka"
send_image("moka_photo", 180, 100, 50, labels=["moka"])

# 2. Montrer image similaire ‚Üí ARIA dit "moka"
send_image("test", 175, 95, 55)
# ‚Üí Recognition: "Je reconnais: moka ! (vu 2 fois)"
# ‚Üí Log: üëÅÔ∏è‚Üíüí¨ VISUAL RECOGNITION: ARIA sees 'moka'
```

ARIA peut maintenant apprendre √† reconna√Ætre Moka et Obrigada sur photo !

### Session 14 - M√©ta-apprentissage (AGI)

**ARIA apprend √† apprendre** - Plus besoin d'attendre le feedback externe !

**Nouveau module `meta_learning.rs`** :
- `InternalReward` : ARIA s'auto-√©value (coh√©rence, surprise, satisfaction)
- `ExplorationStrategy` : 6 strat√©gies d'exploration (semantic, emotional, cross-category, random...)
- `MetaLearner` : s√©lectionne la meilleure strat√©gie et apprend de ses r√©sultats
- `ProgressTracker` : conscience de son propre progr√®s (trend: improving/stable/declining)
- `InternalGoal` : ARIA se fixe ses propres objectifs

**Flux m√©ta-apprentissage** :
```
ARIA explore ‚Üí InternalReward calcule score ‚Üí MetaLearner apprend ‚Üí Meilleure strat√©gie
```

**Nouveau endpoint HTTP** :
```bash
curl http://localhost:8765/meta  # Stats du m√©ta-apprentissage
```

**Logs observ√©s** :
```
üß† META: Selected strategy 'semantic'
üîç EXPLORING (semantic): trying 'chat+moka'
‚úÖ INTERNAL REWARD: 0.54 (good) - coherence:0.72 surprise:0.35
üéØ NEW GOAL: R√©ussir 5 explorations
```

ARIA n'attend plus "Bravo!" - elle sait elle-m√™me si une exploration √©tait int√©ressante.

### Session 13 - Exploration guid√©e par la curiosit√© (AGI)

**Nouveau syst√®me d'auto-apprentissage** :
- `ExplorationResult` : enregistre chaque combinaison de mots essay√©e
- `exploration_history` : m√©moire des explorations dans LongTermMemory
- `get_novel_combination()` : trouve des combinaisons jamais essay√©es
- Feedback renforce les explorations r√©ussies

**Corrections** :
- Boredom decay appel√© dans `tick()` (l'ennui grandit sans interaction)
- Priorit√© bored > lonely (exploration prioritaire)
- Cooldown s√©par√© pour parole spontan√©e (`last_spontaneous_tick`)

**Logs observ√©s** :
```
üîç EXPLORING: trying 'joli+chat'
‚úÖ EXPLORATION SUCCESS: 'joli+aime' (1/1)
```

ARIA explore des combinaisons, apprend du feedback, d√©veloppe ses pr√©f√©rences. Premier pas vers l'AGI.

### Session 12 - GPU Backend & Migration V2

**Changements majeurs** :
- SubstrateV2 devient le substrate par d√©faut (renomm√© en `Substrate`)
- GPU backend int√©gr√© via wgpu/Vulkan (AMD Radeon NAVI14 test√©)
- Suppression des fichiers obsol√®tes (`cell.rs`, `substrate_old.rs`, `connection.rs`)
- Suppression des feature flags
- `aria_compute::create_backend()` auto-s√©lectionne GPU ou CPU

**Commandes** :
```bash
task brain          # Auto GPU/CPU
ARIA_BACKEND=gpu task brain  # Force GPU
```
